{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from ipywidgets import interact, IntSlider, Button\n",
    "from ipywidgets import interact_manual\n",
    "# import sympy as sym\n",
    "# from sympy import S,N\n",
    "# import locale\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from keras.utils import np_utils #one hot encoding\n",
    "from keras.models import Sequential #神經網路的框架keras.models\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Flatten # 將資料展平\n",
    "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta\n",
    "from keras.models import model_from_json\n",
    "from keras.datasets import mnist # mnist內 包含手寫測試資料\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.layers import Dropout\n",
    "\n",
    "import matplotlib.image as mpimg #import image file\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 training data with size 28 x 28\n",
      "There are 10000 testing  data with size 28 x 28\n",
      "x_train.max =  1.0 \n",
      "x_train.min =  0.0 \n",
      "y_test[0] =  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\n",
      "\n",
      "y_test_even_odd統計:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([4926.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        5074.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train0, y_train0), (x_test0, y_test0) = mnist.load_data()\n",
    "print(\"There are %d training data with size %d x %d\" %x_train0.shape)\n",
    "print(\"There are %d testing  data with size %d x %d\" %x_test0.shape)\n",
    "# y_test0.shape\n",
    "\n",
    "x_train = x_train0.reshape(x_train0.shape[0], -1)\n",
    "x_test = x_test0.reshape(x_test0.shape[0], -1)\n",
    "x_train -= x_train.min()\n",
    "x_train = x_train/x_train.max()\n",
    "y_train = np_utils.to_categorical(y_train0, 10)\n",
    "y_test = np_utils.to_categorical(y_test0, 10)\n",
    "\n",
    "print(\"x_train.max = \", x_train.max(), \"\\nx_train.min = \", x_train.min(), \"\\ny_test[0] = \", y_test[0])\n",
    "\n",
    "y_train_even_odd = np.ones_like(y_train0)\n",
    "y_train_even_odd[y_train0%2==0] = 0\n",
    "\n",
    "y_test_even_odd = np.ones_like(y_test0) # return 全部都是1的矩陣，shape跟y_test一樣\n",
    "y_test_even_odd[y_test0%2==0] = 0\n",
    "\n",
    "print(\"\\n\\ny_test_even_odd統計:\")\n",
    "plt.hist(y_test_even_odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8762ee76a8234957aa03d028837cddb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Data Index', max=59999), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotNumber(idx)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plotNumber(idx):\n",
    "    plt.imshow(x_train0[idx], 'Greys')\n",
    "    plt.title(\"Number: %d\\n Evev/odd label: %d\" %(y_train0[idx], y_train_even_odd[idx]))\n",
    "    plt.axis('off')\n",
    "interact(plotNumber, idx=IntSlider(value=0, description='Data Index', min=0, max=x_train0.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\奎佑\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 80)                20080     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                810       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 538,640\n",
      "Trainable params: 538,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "first_layer = [Dense(500, input_dim=784), Activation('relu')]\n",
    "second_layer = [Dense(250), Activation('relu')]\n",
    "third_layer = [Dense(80), Activation('relu')]\n",
    "fourth_layer = [Dense(10), Activation('softmax')]\n",
    "\n",
    "model = Sequential(first_layer + second_layer + third_layer + fourth_layer)\n",
    "# 這種方法可以複製某幾層是從別的已經訓練好的model來的\n",
    "# 就是「轉移學習」！\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\奎佑\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 0.0742 - acc: 0.4931\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0341 - acc: 0.8081\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0205 - acc: 0.8826\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0165 - acc: 0.9006\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0146 - acc: 0.9099\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0134 - acc: 0.9167\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0125 - acc: 0.9213\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0118 - acc: 0.9261\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0112 - acc: 0.9294\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0107 - acc: 0.9328\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0102 - acc: 0.9361\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0098 - acc: 0.9389 1s - loss:\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0094 - acc: 0.9411\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0091 - acc: 0.9436\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0088 - acc: 0.9453\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.0085 - acc: 0.9478 0s - loss: 0.0085 - acc: 0.9\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0082 - acc: 0.9492\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0080 - acc: 0.9512\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0077 - acc: 0.9527\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0075 - acc: 0.9537\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0073 - acc: 0.9553\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0071 - acc: 0.9573\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0069 - acc: 0.9581\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0067 - acc: 0.9591\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 0.0065 - acc: 0.9607\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0064 - acc: 0.9613\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0062 - acc: 0.9624\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 0.0060 - acc: 0.9636\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0059 - acc: 0.9642\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.0057 - acc: 0.9654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d317fe21d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.087), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=100, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 68us/step\n",
      "loss: 0.008193092489594302\n",
      "正確率 0.9589\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('loss:', score[0])\n",
    "print('正確率', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 開始轉移學習\n",
    "\n",
    "我們要來用上面這個已經學習好的model來做新的even_odd_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 80)                20080     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 162       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 537,992\n",
      "Trainable params: 162\n",
      "Non-trainable params: 537,830\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "even_odd_fourth_layer = [Dense(2), Activation('softmax')]\n",
    "\n",
    "# 可以讓我們不訓練這幾層!!\n",
    "first_layer[0].trainable = False\n",
    "second_layer[0].trainable = False\n",
    "third_layer[0].trainable = False\n",
    "\n",
    "even_odd_model = Sequential(first_layer + second_layer + third_layer + even_odd_fourth_layer)\n",
    "even_odd_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可以看到\n",
    "\n",
    "Total params: 537,992\n",
    "\n",
    "Trainable params: 162 <-------------需要訓練的params非常少\n",
    "\n",
    "Non-trainable params: 537,830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0703 - acc: 0.9069\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0525 - acc: 0.9327\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0482 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0454 - acc: 0.9421\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0435 - acc: 0.9447\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0422 - acc: 0.9465\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0413 - acc: 0.9475\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0403 - acc: 0.9488\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0396 - acc: 0.9502\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0392 - acc: 0.9498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d317fe2438>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_odd_model.compile(loss='mse', optimizer=SGD(lr=0.087), metrics=['accuracy'])\n",
    "even_odd_model.fit(x_train, np_utils.to_categorical(y_train_even_odd, 2), batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 69us/step\n",
      "loss: 0.04797879063578556\n",
      "正確率 0.9518\n"
     ]
    }
   ],
   "source": [
    "even_odd_score = even_odd_model.evaluate(x_test, np_utils.to_categorical(y_test_even_odd, 2))\n",
    "print('loss:', even_odd_score[0])\n",
    "print('正確率', even_odd_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轉移學習成功"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資源\n",
    "\n",
    "雖然這個模型看起來很隨便，但轉移學習的模型**差不多**都是這樣建立的，實際上， Keras 亦提供許多被證實有良好表現且訓練好 (pre-trained) 的模型，如:\n",
    "\n",
    "* Xception\n",
    "* VGG16\n",
    "* VGG19   (VGG為早期物件辨識的模型，但太胖)\n",
    "* ResNet50    (ResNet50還不錯，但也有點胖)\n",
    "* InceptionV3\n",
    "* InceptionResNetV2\n",
    "* MobileNet\n",
    "* DenseNet\n",
    "* NASNet\n",
    "\n",
    "詳細的使用方式可參考 Keras Documentation: https://keras.io/applications/\n",
    "(有範例告訴我們怎麼讀去權重、拆layers等)\n",
    "\n",
    "但使用這些模型進行轉移學習，**可能**需要 ``Sequential`` 以外寫法，以及更多神經網路的建構技巧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
