{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from ipywidgets import interact, IntSlider, Button\n",
    "from ipywidgets import interact_manual\n",
    "# import sympy as sym\n",
    "# from sympy import S,N\n",
    "# import locale # 調整數字格式\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from keras.utils import np_utils #one hot encoding\n",
    "from keras.models import Sequential #神經網路的框架keras.models\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "# from keras.layers import Flatten # 將資料展平\n",
    "# from keras.layers import Conv2D, MaxPool2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta\n",
    "from keras.models import model_from_json\n",
    "# from keras.datasets import mnist # mnist內 包含手寫測試資料\n",
    "from keras.datasets import imdb # imdb內 包含電影評論資料\n",
    "from keras.preprocessing import sequence # 用來同整不同長度的電影評論，多的擷掉，少的補 0\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# #for Functional API\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import concatenate, add\n",
    "# #for Functional API transfer learning\n",
    "# from keras.layers.core import Lambda\n",
    "# from keras import backend as K\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.layers import Dropout\n",
    "\n",
    "# import matplotlib.image as mpimg #import image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train0, y_train0), (x_test0, y_test0) = imdb.load_data(num_words = 10000)\n",
    "# num_words 代表要擷取多少常用字，其餘的字當作不認識\n",
    "print(\"There are %d training data with size %d x %d\" %x_train0.shape)\n",
    "print(\"There are %d testing  data with size %d x %d\" %x_test0.shape)\n",
    "print(\"There are %d training label with size %d x %d\" %y_train0.shape)\n",
    "print(\"There are %d testing  label with size %d x %d\" %y_test0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train0, maxlen = 150)\n",
    "x_test = sequence.pad_sequences(x_train0, maxlen = 150)\n",
    "# x_train -= x_train.min()\n",
    "# x_train = x_train/x_train.max()\n",
    "y_train = np_utils.to_categorical(y_train0, 10)\n",
    "y_test = np_utils.to_categorical(y_test0, 10)\n",
    "\n",
    "# print(\"x_train.max = \", x_train.max(), \"\\nx_train.min = \", x_train.min(), \"\\ny_test[0] = \", y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 32 # 希望用 Embedding 來做 dimension reduction 將資料降至N維\n",
    "K = 20 # 決定LSTM 神經元個數 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
