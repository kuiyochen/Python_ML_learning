{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from ipywidgets import interact, IntSlider, Button\n",
    "from ipywidgets import interact_manual\n",
    "# import sympy as sym\n",
    "# from sympy import S,N\n",
    "# import locale # 調整數字格式\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from keras.utils import np_utils #one hot encoding\n",
    "from keras.models import Sequential #神經網路的框架keras.models\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM\n",
    "# from keras.layers import Flatten # 將資料展平\n",
    "# from keras.layers import Conv2D, MaxPool2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "from keras.models import model_from_json\n",
    "# from keras.datasets import mnist # mnist內 包含手寫測試資料\n",
    "from keras.datasets import imdb # imdb內 包含電影評論資料\n",
    "from keras.preprocessing import sequence # 用來同整不同長度的電影評論，多的擷掉，少的補 0\n",
    "# from keras.preprocessing.text import Tokenizer # 轉換文字成數字\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# #for Functional API\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import concatenate, add\n",
    "# #for Functional API transfer learning\n",
    "# from keras.layers.core import Lambda\n",
    "# from keras import backend as K\n",
    "\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# import matplotlib.image as mpimg #import image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25000 training data\n",
      "There are 25000 testing  data\n",
      "There are 25000 training label\n",
      "There are 25000 testing  label\n",
      "\n",
      "the text of x_train0[0] = \n",
      "  this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert *** is an amazing actor and now the same being director *** father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for *** and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also *** to the two little boy's that played the *** of norman and paul they were just brilliant children are often left out of the *** list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all  ...\n",
      "\n",
      "y_train0[0] = \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "INDEX_FROM = 3 # 預設本來就是 3 ，意思是 word to int 的 int一定大於等於 3\n",
    "NUM_WORDS = 10000 # num_words 代表要擷取多少常用字，其餘的字當作不認識\n",
    "(x_train0, y_train0), (x_test0, y_test0) = imdb.load_data(num_words = NUM_WORDS, index_from=INDEX_FROM)\n",
    "word_to_id = imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "id_to_word[0] = \"\"\n",
    "id_to_word[1] = \"\"\n",
    "id_to_word[2] = \"***\"\n",
    "\n",
    "def convert_inverse_to_text(list_of_int):\n",
    "    return ' '.join(id_to_word[id] for id in list_of_int )\n",
    "\n",
    "print(\"There are %d training data\" %x_train0.shape)\n",
    "print(\"There are %d testing  data\" %x_test0.shape)\n",
    "print(\"There are %d training label\" %y_train0.shape)\n",
    "print(\"There are %d testing  label\" %y_test0.shape)\n",
    "print(\"\\nthe text of x_train0[0] = \\n\", convert_inverse_to_text(x_train0[0]), \" ...\\n\\ny_train0[0] = \\n\", y_train0[0])\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train0, maxlen = 150)\n",
    "x_test = sequence.pad_sequences(x_test0, maxlen = 150)\n",
    "y_train = y_train0\n",
    "y_test = y_test0\n",
    "# y_train = np_utils.to_categorical(y_train0, 2)\n",
    "# y_test = np_utils.to_categorical(y_test0, 2)\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\奎佑\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\奎佑\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 500)         5000000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 500)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30)                63720     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 5,063,751\n",
      "Trainable params: 5,063,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "N = 500 # 希望用 Embedding 來做 dimension reduction 將資料降至N維\n",
    "K = 30 # 決定LSTM 神經元個數 K\n",
    "# 有人說：當 N >> K 時會提升相關的準確率？？？\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(NUM_WORDS, N))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(LSTM(K))\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM cell\n",
    "黃色的地方(共4個)自己就有 weight 跟 bias  \n",
    "輸入有 $h_{t-1}$ 跟 $x_t$ ，共(K+N)個輸入  \n",
    "也就是~1個黃色的地方就會有 K+N 個輸入的weight + 1個bias  \n",
    "所以一個 LSTM cell 就會有 4*(K+N+1)個params\n",
    "\n",
    "4240 = 4(K+N+1)K\n",
    "\n",
    "<!-- <div style=\"width: 500px; height: 240px; overflow: hidden\"> -->\n",
    "<img src=\"https://cdn-images-1.medium.com/max/900/1*ZX2mVCwMIOhftEaf4FTOYQ.png\" width=\"500\" title=\"LSTM\">\n",
    "<!-- <\\div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更多關於 RNN vs GRU vs LSTM\n",
    "[Simple RNN vs GRU vs LSTM :- Difference lies in More Flexible control](https://medium.com/@saurabh.rathor092/simple-rnn-vs-gru-vs-lstm-difference-lies-in-more-flexible-control-5f33e07b1e57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\奎佑\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 139s 6ms/step - loss: 0.4005 - acc: 0.8203\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 146s 6ms/step - loss: 0.2400 - acc: 0.9066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a72d674ef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 26s 1ms/step\n",
      "loss: 0.3210943642377853\n",
      "正確率 0.86788\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('loss:', score[0])\n",
    "print('正確率', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
